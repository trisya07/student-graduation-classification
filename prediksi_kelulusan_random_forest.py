# -*- coding: utf-8 -*-
"""prediksi kelulusan Random forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlaiDg7T5g4h6WEik39ipRUxVF4KSaPT

# Klasifikasi Tingkat Kelulusan Mahasiswa Menggunakan Algoritma Random Forest
Proyek ini bertujuan untuk memprediksi apakah seorang mahasiswa akan lulus tepat waktu atau tidak tepat waktu berdasarkan data akademik dan demografis. Model klasifikasi diterapkan untuk membantu perguruan tinggi dalam mengidentifikasi mahasiswa yang berpotensi terlambat lulus.

## 1. Import Library
Pada tahap ini, dilakukan import library yang dibutuhkan dalam proyek klasifikasi, seperti pandas dan numpy untuk analisis data, seaborn dan matplotlib untuk visualisasi, scikit-learn untuk model klasifikasi dan evaluasi, serta imblearn untuk menangani ketidakseimbangan data.
"""

!pip install optuna

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Model machine learning
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Evaluasi model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay

# Pra-pemrosesan data
from sklearn.preprocessing import LabelEncoder

# Menangani data tidak seimbang
from imblearn.over_sampling import SMOTE

# Fine Tuning
import optuna

"""## Load Dataset
Pada tahap ini, dua dataset diunduh langsung dari repository GitHub dalam format .csv, yaitu:

[`ms_lulusan_fix.csv`](https://github.com/trisya07/student-graduation-classification/blob/main/ms_lulusan_fix.csv): Berisi data mahasiswa lulusan, seperti NIM, prodi, status kelulusan, tahun masuk, tahun lulus, dan atribut demografis lainnya.

[`transkip_nilai_fix.csv`](https://github.com/trisya07/student-graduation-classification/blob/main/transkip_nilai_fix.csv): Berisi data transkrip nilai mahasiswa, termasuk kode mata kuliah, nama mata kuliah, nilai, SKS, dan semester.

Kedua dataset ini akan digunakan untuk menggabungkan data akademik dengan data kelulusan dalam analisis klasifikasi kelulusan mahasiswa.
"""

# memuat dataset demografi mahasiswa
url1 = 'https://raw.githubusercontent.com/trisya07/student-graduation-classification/main/ms_lulusan_fix.csv'
df_lulusan = pd.read_csv(url1)

# memuat dataset akademik mahasiswa
url2 = 'https://raw.githubusercontent.com/trisya07/student-graduation-classification/main/transkip_nilai_fix.csv'
df_transkip = pd.read_csv(url2)

# Menampilkan lima data pertama dari df_transkip
df_transkip.head()

df_lulusan.head()

"""## Statistik Deskriptif Dataset
Tahap ini digunakan untuk melihat ringkasan statistik dari seluruh kolom dalam dataset dan melihat tipe data pada info(). Tujuannya adalah untuk memahami distribusi awal data, mendeteksi potensi nilai kosong, data duplikat, atau data tidak konsisten sebelum dilakukan pembersihan.
"""

print("Data Transkip")
df_transkip.info()

print("Data Lulusan")
df_lulusan.info()

print ("-----------------DATA TRANSKIP------------------------")
df_transkip.describe(include='all')

print("----------------------------Data Lulusan---------------------------")
df_lulusan.describe(include='all')

"""## Pembersihan data

### pengecekan nilai missing value
agar dapat memutuskan tindakan selanjutnya untuk pembersihan data jika terdapat missing value agar memepermudah kualitas data baik
"""

print("DATA TRANSKIP")
# menampilkan nilai yang missing value
df_transkip.isnull().sum()

print("DATA LULUSAN")
df_lulusan.isnull().sum()

"""### Membersihkan missing Value
1. mengganti kolom nama_mk yang missing value dengan nilai yang sesuai dengan kolom nama_mk_indo yang sesuai dengan kode_mknya
2. menghapus kolom nama_mk_indo dan nama_mk_ing karena hanya menyebutkan perbedaan bahasa, sehingga perlu dihapus untuk menghilangkan rendudansi data
"""

# menampilkan data yang missing value
df_transkip[df_transkip.isnull().any(axis=1)]

# mlihat data dengan kode mk FM1190035
df_transkip[df_transkip['kode_mk'] == 'FM1190035']

# mengganti nilai yang kosong yang kode_mknya FM1190035 menjadi "FARMAKOTERAPI INFEKSI, MATA, PERNAFASAN, TULANG DAN SENDI"
df_transkip.loc[df_transkip['kode_mk'] == 'FM1190035', 'nama_mk'] = "FARMAKOTERAPI INFEKSI, MATA, PERNAFASAN, TULANG DAN SENDI"
# menghapus kolom nama_mk_indo dan nama_mk _ing
df_transkip.drop(['nama_mk_indo', 'nama_mk_ing'], axis=1, inplace=True)

"""### Cek Duplikasi data untuk memastikan tidak ada rendudasi data"""

# cek duplikat df_transkip
print(f"Data Duplikat Data Transkip: {df_transkip.duplicated().sum()}")
# cek duplikat df_lulusan
print(f"Data Duplikat Data Lulusan: {df_lulusan.duplicated().sum()}")

"""### mengubah tipe data tanggal_lulus dan tgl_masuk menjadi datetime
Konversi ini bertujuan untuk memudahkan proses labeling nanti yang menghitung dari durasi perkuliahan yang dijalani
"""

# Konversi kolom 'tanggal_lulus' dan 'tgl_masuk' ke format datetime
df_lulusan['tanggal_lulus'] = pd.to_datetime(df_lulusan['tanggal_lulus'], format='%Y-%m-%d')
df_lulusan['tgl_masuk'] = pd.to_datetime(df_lulusan['tgl_masuk'], format='%Y-%m-%d')

"""## Visualisasi EDA untuk lebih memahami dataset"""

# Membuat subplots dalam satu baris dengan 6 kolom
fig, axes = plt.subplots(1, 5, figsize=(20, 5))  # 1 baris, 5 kolom

# Visualisasi distribusi status_pegawai
df_lulusan['status_pegawai'].value_counts().plot(kind='bar', ax=axes[0])
axes[0].set_title('Distribusi Status Pegawai')

# Visualisasi data jenis kelamin
df_lulusan['jenis_kelamin'].value_counts().plot(kind='bar', ax=axes[1])
axes[1].set_title('Distribusi Jenis Kelamin')

# Visualisasi data status_masuk
df_lulusan['status_masuk'].value_counts().plot(kind='bar', ax=axes[2])
axes[2].set_title('Distribusi Status Masuk')

# Visualisasi distribusi prodi
df_lulusan['prodi'].value_counts().plot(kind='bar', ax=axes[3])
axes[3].set_title('Distribusi Prodi')

# Visualisasi distribusi grade
df_transkip['grade'].value_counts().plot(kind='bar', ax=axes[4])
axes[4].set_title('Distribusi Grade')

# Menampilkan semua plot
plt.tight_layout()  # Untuk menghindari tumpang tindih
plt.show()

"""## Pemeriksaan Nilai Tidak Valid pada Kolom `semester`
Dari hasil statistik deskriptif, ditemukan bahwa kolom semester memiliki nilai minimum 0. Hal ini tidak sesuai dengan logika akademik karena semester seharusnya dimulai dari 1.
Oleh karena itu, dilakukan pemeriksaan pada kolom `semester` dan melihat datanya.
Tujuannya adalah untuk mengidentifikasi keberadaan dan frekuensi nilai tidak valid (seperti 0) agar dapat diputuskan apakah akan dihapus atau diperbaiki pada tahap pra-pemrosesan data.
"""

# cari data yang semester 0
df_transkip[df_transkip['semester'] == 0]

"""## mengidentifikasi Nilai Semester yang valid
Berdasarkan hasil eksplorasi data, ditemukan bahwa kolom semester memiliki nilai tidak valid yaitu 0 210 data, cukup banyak. Secara akademik, semester seharusnya bernilai minimal 1. Oleh karena itu, dilakukan identifikasi dan perbaikan terhadap data tersebut agar tidak memengaruhi kualitas model klasifikasi.

Langkah-langkah yang dilakukan:

1. Mengidentifikasi semua kode_mk (kode mata kuliah) yang memiliki semester bernilai 0.
2. Melihat distribusi semester untuk setiap kode_mk tersebut. disini hanya menampilkan 3 data saja.
"""

# Identifikasi semua kode mata kuliah yang memiliki semester 0
kode_mk_semester_0 = df_transkip[df_transkip['semester'] == 0]['kode_mk'].unique()

# Tampilkan contoh kode mk yang awalnya semester 0 dan ternyata muncul di semester lain
# kode_mk_semester_0[:3] mengambil 3 elemen pertama dari array kode_mk_semester_0
for kode_mk in kode_mk_semester_0[:3]:
    print(f"{kode_mk}: {df_transkip[df_transkip['kode_mk'] == kode_mk]['semester'].unique()}")

"""## Memperbaiki kolom semester menjadi nilai valid
proses di atas terlihat bahwa kode_mk tersebut muncul di semester valid lain, sehingga semester 0 dapat dikoreksi, kemungkinan perbedaan ini dikarenakan salah penulisan format, sehingga dilakukan penyesuaian format pada kolom `kode_mk` seperti menghapus spasi yang tidak perlu dan mengubah menjadi huruf kapital. Mengganti semester 0 dengan semester paling sering (mode) dari masing-masing kode_mk. Mode dipilih karena merepresentasikan semester yang paling umum untuk mata kuliah tersebut.
"""

# menyesuaikan format kode_mk yang tepat
df_transkip['kode_mk'] = df_transkip['kode_mk'].astype(str).str.strip().str.upper()

# Identifikasi semua kode mata kuliah yang memiliki semester 0
kode_mk_semester_0 = df_transkip[df_transkip['semester'] == 0]['kode_mk'].unique()

# Iterasi untuk menemukan nilai semester yang seharusnya berdasarkan data yang ada
for kode_mk in kode_mk_semester_0:
    # Temukan nilai semester yang paling umum atau pertama kali muncul
    semester_terbanyak = df_transkip[df_transkip['kode_mk'] == kode_mk]['semester'].mode()[0]

    # Ubah nilai semester yang sesuai
    df_transkip.loc[df_transkip['kode_mk'] == kode_mk, 'semester'] = semester_terbanyak

# Cek hasil perubahan
df_transkip[df_transkip['semester'] == 0]

"""## menghapus data yang semesternya 0
sisa dari data yang kolom semesternya masih bernilai 0 dianggap memang tidak mempunyai nilai valid sehingga dilakukan penghapusan agar optimal
"""

# hapus data yang semsester 0
df_transkip = df_transkip[df_transkip['semester'] != 0]

df_transkip.shape[0]

"""## Perhitungan IPS Mahasiswa per Semester dan Penggabungan Data
Tahapan ini digunakan untuk menghitung nilai IPS (Indeks Prestasi Semester) tiap mahasiswa berdasarkan data transkrip nilai.
1. Menghitung IPS
> IPS dihitung dari total perkalian antara nilai grade dan SKS mata kuliah, lalu dibagi dengan total SKS pada semester tersebut. Pengelompokan dilakukan berdasarkan nim dan semester.

2. Mengubah Format Tabel
> Hasil IPS diubah dari bentuk baris (setiap baris = satu semester) menjadi bentuk kolom (setiap kolom = satu semester), sehingga memudahkan dalam analisis dan modeling.

3. Penggabungan dengan Data Lulusan
> Data IPS yang telah diproses digabungkan dengan data mahasiswa lulusan berdasarkan kolom nim agar diperoleh satu dataset utuh yang berisi informasi nilai dan status kelulusan.
"""

# menghitung ips
ips_df = df_transkip.groupby(['nim', 'semester']).apply(
    lambda x: round((x['nilai_grade'] * x['sks_mk']).sum() / x['sks_mk'].sum(), 2)
).reset_index(name='IPS')

# Mengubah format dari baris ke kolom
ips_df = ips_df.pivot(index='nim', columns='semester', values='IPS').reset_index()
ips_df.columns = ['nim'] + [f'IPS SMT{col}' for col in ips_df.columns[1:]]

# Gabungkan dengan data ms_lulusan berdasarkan NIM
merged_df = pd.merge(ips_df, df_lulusan, on='nim', how='left')
merged_df.head()

"""## Penanganan Kolom IPS SMT9
Beberapa mahasiswa memiliki nilai hingga semester 9, namun sebagian besar hanya sampai semester 8. Karena IPS SMT9 hanya muncul pada sedikit kasus maka dilakukan langkah berikut:
1. Nilai IPS SMT9 digantikan dengan nilai IPS SMT8 jika nilai IPS SMT9 tidak kosong.
2. Setelah disesuaikan, kolom IPS SMT9 dihapus agar data tetap konsisten hanya sampai IPS SMT8.
sehingga pada penelitian ini fokusnya hanya dari IPS semester 1-8 agar data konsisten
"""

merged_df['IPS SMT9'] = merged_df.apply(lambda row: row['IPS SMT9'] if pd.isna(row['IPS SMT9']) else row['IPS SMT8'], axis=1)
merged_df.drop(columns=['IPS SMT9'], inplace=True)
merged_df

"""## Perhitungan Lama Studi dan Status Kelulusan Tepat Waktu
Pada tahap ini dilakukan beberapa transformasi untuk menghitung durasi kuliah setiap mahasiswa dan menentukan apakah mereka lulus tepat waktu yang akan menjadi label klasifikasi nanti:
1. Menghitung Lama Studi
> Selisih antara tanggal masuk dan tanggal lulus dihitung dan diubah menjadi format "X Tahun Y Bulan" lalu disimpan di kolom Lama Kuliah.

2. Konversi ke Format Numerik
> Format "X Tahun Y Bulan" diubah ke bentuk numerik desimal (misalnya 3 tahun 6 bulan menjadi 3.5) agar dapat digunakan untuk klasifikasi.

3. Penentuan Kelulusan Tepat Waktu
> Jika mahasiswa lulus dalam rentang 3.5 hingga kurang dari 5 tahun, maka dianggap tepat waktu (1), jika tidak maka tidak tepat waktu (0).

4. Pembersihan Kolom Sementara
> Kolom Tahun Kuliah dihapus karena hanya digunakan untuk proses klasifikasi.
"""

# Menghitung durasi studi masing-masing mahasiswa dalam tahun dan bulan
def calculate_study_duration(row):
    start_date = pd.to_datetime(row['tgl_masuk'])
    end_date = pd.to_datetime(row['tanggal_lulus'])
    duration = end_date - start_date

    years = duration.days // 365
    months = (duration.days % 365) // 30
    return f"{years} Tahun {months} Bulan"

# Tambahkan kolom 'Lama Kuliah'
merged_df['Lama Kuliah'] = merged_df.apply(calculate_study_duration, axis=1)

# Fungsi untuk mengonversi durasi kuliah ke tahun dengan desimal bulan
def parse_study_duration(duration_str):
    years, months = duration_str.split(' Tahun ')
    years = int(years)
    months = int(months.split(' Bulan')[0])
    return years + months / 12

# Tambahkan kolom 'Tahun Kuliah'
merged_df['Tahun Kuliah'] = merged_df['Lama Kuliah'].apply(parse_study_duration)

# Menambahkan kolom 'Lulus tepat waktu/tidak'
def durasi_kuliah(years):
    return 1 if years >= 3.5 and years < 5 else 0

merged_df['Lulus tepat waktu/tidak'] = merged_df['Tahun Kuliah'].apply(durasi_kuliah)

# Drop kolom 'Tahun Kuliah' karena hanya digunakan untuk perhitungan sementara
merged_df = merged_df.drop(columns=['Tahun Kuliah'])
merged_df.head()

"""## Membandingkan rata-rata IPS dengan label
> Visualisasi ini bertujuan untuk membandingkan rata-rata nilai IPS (Indeks Prestasi Semester) dari semester 1 hingga 8 antara mahasiswa yang lulus tepat waktu dan yang tidak. Prosesnya dimulai dengan mengelompokkan data mahasiswa berdasarkan status kelulusannya, kemudian menghitung rata-rata IPS tiap semester untuk masing-masing kelompok. Data tersebut kemudian diputar (transpose) agar semester dapat digunakan sebagai sumbu X dalam grafik. Selanjutnya dibuat grafik garis (line chart) untuk menampilkan perbandingan tren IPS antar kedua kelompok. Hasil visualisasi ini membantu dalam mengidentifikasi pola prestasi akademik yang berpotensi berpengaruh terhadap kelulusan tepat waktu.
"""

# Menghitung rata-rata IPS berdasarkan status lulus tepat waktu
average_ips = merged_df.groupby('Lulus tepat waktu/tidak')[['IPS SMT1', 'IPS SMT2', 'IPS SMT3', 'IPS SMT4', 'IPS SMT5', 'IPS SMT6', 'IPS SMT7', 'IPS SMT8']].mean()

# Transpose DataFrame untuk kemudahan plot
average_ips = average_ips.T

# Membuat line chart
plt.figure(figsize=(10, 6))
plt.plot(average_ips.index, average_ips[0], marker='o', label='Tidak Tepat Waktu')
plt.plot(average_ips.index, average_ips[1], marker='o', label='Tepat Waktu')

# Menambahkan judul dan label
plt.title('Rata-rata IPS berdasarkan Status Lulus Tepat Waktu')
plt.xlabel('IPS Semester')
plt.ylabel('Rata-rata IPS')
plt.xticks(rotation=45)
plt.legend()
plt.grid()

# Menampilkan plot
plt.show()

"""## distribusi status kelulusan berdasarkan jenis kelamin
> Visualisasi ini bertujuan untuk melihat distribusi jumlah mahasiswa berdasarkan jenis kelamin dan status kelulusannya (tepat waktu atau tidak). Dengan menggunakan countplot, grafik ini menunjukkan perbandingan jumlah mahasiswa laki-laki dan perempuan yang lulus tepat waktu dan yang tidak. Hal ini dapat membantu mengidentifikasi apakah terdapat kecenderungan kelulusan tepat waktu berdasarkan jenis kelamin.
"""

# countplot jenis kelamin berdasarkan lulus tepat waktu atau tidak
sns.countplot(x='jenis_kelamin', hue='Lulus tepat waktu/tidak', data=merged_df)

"""## distribusi status kelulusan berdasarkan status pegawai
Visualisasi ini bertujuan untuk melihat distribusi jumlah mahasiswa berdasarkan jenis kelamin dan status kelulusannya (tepat waktu atau tidak).
status pegawai ini berisi nilai 0 yaitu mahasiswa tidak bekerja dan 1 untuk mahasiswa bekerja.
Dengan menggunakan countplot, grafik ini menunjukkan perbandingan jumlah mahasiswa laki-laki dan perempuan yang lulus tepat waktu dan yang tidak. Hal ini dapat membantu mengidentifikasi apakah terdapat kecenderungan kelulusan tepat waktu berdasarkan jenis kelamin.
"""

plt.figure(figsize=(12, 8))
sns.countplot(x='status_pegawai', hue='Lulus tepat waktu/tidak', data=merged_df)

"""## Distribusi Kelulusan Berdasarkan Tahun Lahir
> Visualisasi ini bertujuan untuk melihat distribusi kelulusan mahasiswa berdasarkan tahun lahir, dengan kategori kelulusan tepat waktu atau tidak. Untuk itu, digunakan countplot dari library Seaborn, di mana sumbu X mewakili tahun lahir dan warna batang (hue) menunjukkan status kelulusan. Langkah pertama adalah memastikan bahwa kolom tahun_lahir dan Lulus tepat waktu/tidak tersedia dan bertipe data yang sesuai. Setelah itu, dibuat plot batang untuk menampilkan jumlah mahasiswa dalam setiap tahun lahir yang lulus tepat waktu maupun tidak. Jika tahun lahir terlalu banyak dan membuat visualisasi tidak jelas, maka data dapat dikelompokkan ke dalam rentang tahun menggunakan metode pd.cut. Hasil visualisasi ini memberikan gambaran awal apakah ada pola atau kecenderungan kelulusan yang berkaitan dengan tahun lahir mahasiswa.
"""

plt.figure(figsize=(12,6))
sns.countplot(data=merged_df, x='tahun_lahir', hue='Lulus tepat waktu/tidak')
plt.title('Distribusi Kelulusan Berdasarkan Tahun Lahir')
plt.xticks(rotation=45)
plt.show()

"""## Distribusi Kelulusan Berdasarkan Prodi
> Visualisasi ini bertujuan untuk menunjukkan distribusi kelulusan tepat waktu mahasiswa berdasarkan program studi (prodi). Dengan menggunakan countplot, grafik ini membandingkan jumlah mahasiswa dari tiap prodi yang lulus tepat waktu dan yang tidak. Hasil visualisasi ini dapat memberikan gambaran apakah terdapat perbedaan signifikan antara program studi dalam hal ketepatan waktu kelulusan mahasiswa.
"""

plt.figure(figsize=(12, 10))
sns.countplot(x='prodi', hue='Lulus tepat waktu/tidak', data=merged_df)

"""## Identifikasi dan Visualisasi Nilai Ekstrem (Outliers)
> Pada tahap ini, kita melakukan identifikasi nilai ekstrem (outliers) pada kolom numerik dalam dataset. Nilai ekstrem adalah data yang berada jauh di luar rentang nilai yang diharapkan, yang dapat mempengaruhi hasil analisis dan model.

> Langkah pertama adalah menghitung rata-rata (mean) dan deviasi standar (standard deviation) dari setiap kolom numerik. Kemudian, rentang normal ditentukan dengan mengurangi tiga kali deviasi standar dari rata-rata untuk batas bawah, dan menambahkan tiga kali deviasi standar untuk batas atas. Nilai yang berada di luar rentang ini dianggap sebagai outliers.

> Jika ditemukan outliers, mereka akan dipisahkan dan divisualisasikan menggunakan boxplot dan scatter plot untuk menandai titik-titik data yang dianggap ekstrem dengan warna merah. Visualisasi ini bertujuan untuk memberikan gambaran yang lebih jelas mengenai sebaran data dan keberadaan outliers yang mungkin perlu diatasi sebelum melanjutkan analisis atau modeling.
"""

# Mencari nilai-nilai ekstrem
numeric_columns = merged_df.select_dtypes(include=['number']).columns
for col in numeric_columns:
    mean = merged_df[col].mean()
    std_dev = merged_df[col].std()
    lower_limit = mean - 3 * std_dev
    upper_limit = mean + 3 * std_dev

    outliers = merged_df[(merged_df[col] < lower_limit) | (merged_df[col] > upper_limit)]
    if not outliers.empty:
        # print(f"\nNilai ekstrem dalam kolom '{col}':")
        # print(outliers)
        # Visualisasi nilai ekstrem
        plt.figure(figsize=(10, 6))
        sns.boxplot(x=merged_df[col])
        sns.scatterplot(x=outliers[col], y=[0]*len(outliers), color='red', zorder=10)
        plt.title(f'Visualisasi Nilai Ekstrem dalam Kolom {col}')
        plt.xlabel(col)
        plt.show()

"""## Mengidentifikasi kolom status_masuk
Menggunakan Visualisasi untuk melihat disrubusi dari kolom status_masuk.
Pada status_masuk ada nilai 0 yang berarti mahasiswa reguler dan 1 berarti mahasiswa pindahan. Pada penelitian ini berfokus pada mahasiswa reguler sehingga data pada mahasiswa pindahan dihapus

"""

# visualisasi jumlah kolom status_masuk
merged_df['status_masuk'].value_counts().plot(kind='bar')

merged_df = merged_df.drop(merged_df[merged_df['status_masuk'] == 1].index)

"""##  Penanganan Nilai Tidak Valid pada Kolom Status Pegawai
> Pada tahap ini, ditemukan adanya data pada kolom status_pegawai yang bernilai 2, padahal seharusnya kolom tersebut hanya mengandung dua nilai, yaitu 0 (tidak bekerja) dan 1 (bekerja). Setelah melakukan pencarian, ditemukan bahwa nilai 2 hanya terdapat pada dua data, dengan tahun lahir 1994 dan 1997. Berdasarkan asumsi bahwa mahasiswa dengan tahun lahir tersebut kemungkinan besar sudah memasuki dunia kerja, maka nilai 2 pada kolom status_pegawai tersebut diganti menjadi 1 (bekerja).
"""

# cari data yang status_pegawai bernilai 2
merged_df[merged_df['status_pegawai'] == 2]

# mengganti status_pegawai yang bernilai 2 menjadi nilai 1
merged_df.loc[merged_df['status_pegawai'] == 2, 'status_pegawai'] = 1

"""## Binning Kolom IPS Berdasarkan Median
> Proses binning dilakukan terhadap delapan kolom IPS (Indeks Prestasi Semester) dari semester 1 hingga 8 untuk menyederhanakan nilai numerik menjadi bentuk kategorikal. Setiap kolom diubah berdasarkan nilai median: jika nilai IPS kurang dari atau sama dengan median, maka dikategorikan sebagai 0; jika lebih dari median, dikategorikan sebagai 1. Teknik ini bertujuan untuk mengurangi kompleksitas data numerik dan membantu model klasifikasi dalam memahami perbedaan performa akademik mahasiswa secara lebih terstruktur. Binning juga bermanfaat untuk mengatasi distribusi yang tidak seimbang serta meningkatkan interpretabilitas model dalam konteks prediksi kelulusan tepat waktu.
"""

# Daftar kolom IPS
ips_columns = ['IPS SMT1', 'IPS SMT2', 'IPS SMT3', 'IPS SMT4', 'IPS SMT5', 'IPS SMT6', 'IPS SMT7', 'IPS SMT8']

# Lakukan binning (≤ median → 0, > median → 1)
for col in ips_columns:
    median_value = merged_df[col].median()
    merged_df[col] = merged_df[col].apply(lambda x: 0 if x <= median_value else 1)

"""## Pembuatan dan Encoding Fitur Kategori Usia Berdasarkan Tahun Lahir
Untuk memperkaya informasi demografis dalam dataset, dilakukan proses rekayasa fitur (feature engineering) dengan membuat kolom kategori usia berdasarkan atribut tahun_lahir. Data tahun lahir diklasifikasikan ke dalam tiga kategori usia: ‘Tua’ untuk tahun lahir sebelum 1990, ‘Dewasa’ untuk tahun lahir antara 1990 hingga 1999, dan ‘Muda’ untuk tahun 2000 ke atas. Kategori ini kemudian dikonversi ke bentuk numerik menggunakan metode Label Encoding agar dapat digunakan dalam pemodelan machine learning. Setelah proses encoding, kolom kelompok_usia disisipkan ke dalam DataFrame tepat setelah kolom tahun_lahir untuk menjaga keterkaitan logis antara fitur tersebut. Pendekatan ini bertujuan untuk menilai apakah kategori usia memiliki pengaruh terhadap kemungkinan mahasiswa lulus tepat waktu.
"""

# Membuat kolom kategori usia berdasarkan tahun lahir
def kelompok_usia(tahun):
    if tahun < 1990:
        return 'Tua'
    elif tahun < 2000:
        return 'Dewasa'
    else:
        return 'Muda'

# Terapkan fungsi ke DataFrame
merged_df['kelompok_usia'] = merged_df['tahun_lahir'].apply(kelompok_usia)

# Melakukan Label Encoding terhadap kolom kelompok_usia
encoder = LabelEncoder()
merged_df['kelompok_usia'] = encoder.fit_transform(merged_df['kelompok_usia'])

# Menyusun ulang kolom agar 'kelompok_usia' berada setelah 'tahun_lahir'
kolom = list(merged_df.columns)
kolom.remove('kelompok_usia')
indeks_tahun_lahir = kolom.index('tahun_lahir')
kolom.insert(indeks_tahun_lahir + 1, 'kelompok_usia')
merged_df = merged_df[kolom]

merged_df

"""## Heatmap Korelasi Antar Fitur Numerik
> Visualisasi heatmap ini dibuat untuk melihat hubungan korelasi antar fitur numerik dalam dataset. Langkah pertama adalah menyeleksi kolom-kolom dengan tipe data numerik menggunakan select_dtypes. Setelah itu, digunakan fungsi corr() untuk menghitung matriks korelasi antar kolom numerik tersebut. Hasil korelasi divisualisasikan menggunakan seaborn.heatmap dengan parameter annot=True agar nilai korelasi ditampilkan langsung pada setiap sel. Warna pada heatmap mencerminkan tingkat kekuatan korelasi, dengan skema warna coolwarm yang memudahkan identifikasi hubungan positif maupun negatif. Visualisasi ini berguna untuk memahami hubungan antar variabel dan membantu dalam proses seleksi fitur atau deteksi multikolinearitas sebelum pemodelan.
"""

# buatkan heatmap pada kolom numerik
# kolom numerik sjaa
numeric_columns = merged_df.select_dtypes(include=['number']).columns
plt.figure(figsize=(12, 10))
sns.heatmap(merged_df[numeric_columns].corr(), annot=True, cmap='coolwarm')

"""## Pemilihan fitur dan pembagian dataset
Pada tahap ini dilakukan pemisahan antara fitur (X) dan label (y). Kolom target yaitu 'Lulus tepat waktu/tidak' dipisahkan dan disimpan sebagai variabel y, sedangkan fitur-fitur lainnya disimpan dalam variabel X, dengan menghapus kolom-kolom yang tidak relevan untuk pelatihan model seperti 'nim', 'status_masuk', 'tgl_masuk', 'tanggal_lulus', 'Lama Kuliah', 'predikat', serta IPS semester 8. Selanjutnya, dilakukan pembagian data menjadi 80% untuk data pelatihan dan 20% untuk data pengujian menggunakan fungsi train_test_split dari Scikit-Learn. Parameter random_state=42 digunakan agar hasil pembagian data bersifat reproducible, sementara stratify=y memastikan bahwa proporsi kelas target tetap seimbang pada data pelatihan dan pengujian.
"""

X = merged_df.drop(columns=['Lulus tepat waktu/tidak', 'nim', 'status_masuk', 'tgl_masuk', 'tanggal_lulus', 'Lama Kuliah', 'predikat', 'IPS SMT8', 'tahun_lahir'])
y = merged_df['Lulus tepat waktu/tidak']

# Pembagian data 80% untuk pelatihan dan 20% untuk pengujian secara acak
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# visualisasi distribusi y_train
y_train.value_counts().plot(kind='bar')

# lihat jumlah data y_train untuk nilai 1 dan 0
print(y_train.value_counts())

"""## Penerapan SMOTE
Karena data target tidak seimbang—dengan jumlah mahasiswa yang lulus tepat waktu jauh lebih banyak dibandingkan yang tidak—maka dilakukan oversampling menggunakan metode SMOTE (Synthetic Minority Over-sampling Technique). SMOTE bekerja dengan cara membuat sampel sintetis dari kelas minoritas untuk menyeimbangkan distribusi kelas. Hal ini bertujuan agar model tidak bias terhadap kelas mayoritas dan dapat belajar mengenali pola dari kedua kelas secara seimbang. Setelah diterapkan, jumlah data untuk masing-masing kelas menjadi seimbang, sebagaimana ditunjukkan oleh hasil value_counts() pada label target.
"""

# terapkan smote
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)
# cek jumlah data setelah smote
print(y_train.value_counts())

"""## Pemodelan Menggunakan Random Forest
Pada tahap ini, dilakukan pemodelan untuk memprediksi ketepatan waktu kelulusan mahasiswa dengan menggunakan algoritma Random Forest Classifier.
Model Random Forest Classifier diinisialisasi dengan parameter random_state=42 untuk memastikan hasil yang konsisten. Model ini kemudian dilatih menggunakan data pelatihan (X_train, y_train) yang sebelumnya telah di-resample dengan teknik SMOTE guna mengatasi ketidakseimbangan kelas. Setelah pelatihan, dilakukan prediksi terhadap data pelatihan dan data pengujian untuk mengevaluasi performa model. Akurasi dari kedua data tersebut dihitung dan ditampilkan untuk mengetahui seberapa baik model dalam mengenali pola. Selain itu, ditampilkan juga classification report yang memuat metrik precision, recall, dan f1-score pada data pengujian, serta confusion matrix yang divisualisasikan menggunakan heatmap untuk memberikan gambaran yang jelas terhadap distribusi hasil prediksi terhadap nilai aktual.
"""

# Inisialisasi model Random Forest
rf_model = RandomForestClassifier(random_state=42)

# Melatih model dengan data pelatihan yang sudah di-resample menggunakan SMOTE
rf_model.fit(X_train, y_train)

# Prediksi pada data pelatihan (training) dan pengujian (testing)
y_train_pred = rf_model.predict(X_train)
y_test_pred = rf_model.predict(X_test)

# Menghitung akurasi untuk data pelatihan dan pengujian
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

# Menampilkan akurasi
print(f"Akurasi pada data pelatihan: {train_accuracy:.4f}")
print(f"Akurasi pada data pengujian: {test_accuracy:.4f}")

# Menampilkan classification report
print("\nClassification Report pada data pengujian:")
print(classification_report(y_test, y_test_pred))

# Menampilkan confusion matrix untuk data pengujian
cm = confusion_matrix(y_test, y_test_pred)

"""## Tuning Hyperparameter Menggunakan Bayesian Optimization dengan Optuna
Untuk mengoptimalkan kinerja model Random Forest dalam memprediksi ketepatan waktu kelulusan, dilakukan proses hyperparameter tuning menggunakan pendekatan Bayesian Optimization melalui library Optuna. Proses ini bertujuan untuk mencari kombinasi parameter terbaik yang menghasilkan akurasi prediksi tertinggi pada data pengujian. Beberapa parameter yang dituning meliputi jumlah estimators (n_estimators), kedalaman pohon (max_depth), jumlah minimum sampel untuk split (min_samples_split), jumlah minimum sampel di daun (min_samples_leaf), serta metode pemilihan fitur (max_features). Setelah proses optimasi selama 30 iterasi, model terbaik dilatih ulang dengan parameter yang diperoleh, kemudian dievaluasi menggunakan metrik akurasi, classification report, dan confusion matrix.
"""

# Fungsi objektif untuk optimasi
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'max_depth': trial.suggest_int('max_depth', 5, 50),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),
    }

    model = RandomForestClassifier(random_state=42, **params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

# Optimasi hyperparameter
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=30)  # Kamu bisa tambah trial jika perlu

# Ambil parameter terbaik dan latih model akhir
best_params = study.best_params
best_rf_model = RandomForestClassifier(random_state=42, **best_params)
best_rf_model.fit(X_train, y_train)

# Evaluasi
y_train_pred = best_rf_model.predict(X_train)
y_test_pred = best_rf_model.predict(X_test)

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

# Cetak hasil
print(f"Akurasi pada data pelatihan: {train_accuracy:.4f}")
print(f"Akurasi pada data pengujian: {test_accuracy:.4f}")
print("\nClassification Report pada data pengujian:")
print(classification_report(y_test, y_test_pred))

"""## Pengujian Data Baru
Setelah proses pelatihan dan optimasi model Random Forest selesai, langkah selanjutnya adalah melakukan pengujian terhadap data baru untuk mengevaluasi performa model dalam situasi nyata. Data baru yang digunakan merepresentasikan karakteristik mahasiswa dengan beberapa atribut seperti nilai IPS tiap semester, program studi, jenis kelamin, status pegawai, dan kelompok usia berdasarkan tahun lahir.
Proses pengujian diawali dengan pra-pemrosesan data baru agar sesuai dengan format dan transformasi data yang digunakan pada saat pelatihan model. Langkah-langkah yang dilakukan meliputi:

1. Penambahan Kolom Kelompok Usia
> Berdasarkan tahun lahir, individu dikategorikan ke dalam kelompok usia. Untuk tahun lahir 2003, individu termasuk ke dalam kelompok "Muda", yang kemudian dikonversi ke bentuk numerik menggunakan LabelEncoder yang telah di-fit sebelumnya pada data training.

2. Transformasi Nilai IPS
> Semua nilai IPS pada masing-masing semester dikonversi menjadi biner berdasarkan median nilai IPS pada data pelatihan. Jika nilai lebih dari median, maka diberi label 1, sebaliknya 0.

3. Penyusunan Kolom
> Kolom-kolom pada data uji disesuaikan urutannya agar identik dengan kolom yang digunakan pada pelatihan model (X_train.columns).

4. Prediksi
> Data yang sudah diproses kemudian dimasukkan ke dalam model Random Forest hasil optimasi (best_rf_model) untuk memperoleh hasil prediksi apakah mahasiswa tersebut lulus tepat waktu atau tidak.

Hasil dari proses prediksi tersebut ditampilkan dalam bentuk label, yaitu:

- Tepat Waktu jika model memprediksi nilai 1.

- Tidak Tepat Waktu jika model memprediksi nilai 0.



"""

# Data baru mentah
data_baru = {
    'IPS SMT1': 3.70,
    'IPS SMT2': 3.70,
    'IPS SMT3': 3.57,
    'IPS SMT4': 3.89,
    'IPS SMT5': 3.71,
    'IPS SMT6': 3.79,
    'IPS SMT7': 3.82,
    'prodi': 61201,
    'jenis_kelamin': 0,
    'status_pegawai': 0,
    'tahun_lahir': 2003  # untuk kelompok usia
}

# Buat dataframe
df_uji = pd.DataFrame([data_baru])

# Tambah kelompok_usia (label encoded)
df_uji['kelompok_usia'] = 'Muda'
# Use 'encoder' instead of 'label_encoder'
df_uji['kelompok_usia'] = encoder.transform(df_uji['kelompok_usia'])

# Calculate medians from the training data for IPS columns
medians = X_train[['IPS SMT1', 'IPS SMT2', 'IPS SMT3', 'IPS SMT4', 'IPS SMT5', 'IPS SMT6', 'IPS SMT7']].median().to_dict()

# Binning IPS berdasarkan median dari data training
ips_cols = ['IPS SMT1', 'IPS SMT2', 'IPS SMT3', 'IPS SMT4', 'IPS SMT5', 'IPS SMT6', 'IPS SMT7']
for col in ips_cols:
    df_uji[col] = 1 if df_uji[col][0] > medians[col] else 0

# Susun ulang kolom sesuai X_train
df_uji = df_uji[X_train.columns]

# Prediksi
hasil_prediksi = best_rf_model.predict(df_uji)
label = 'Tepat Waktu' if hasil_prediksi[0] == 1 else 'Tidak Tepat Waktu'
print(df_uji)
print(f"Hasil prediksi: {label}")

"""## Analisis Feature Importance pada Model Random Forest
Untuk mengetahui seberapa besar kontribusi masing-masing fitur dalam menentukan prediksi model, dilakukan analisis feature importance menggunakan model Random Forest. Nilai importance dihitung berdasarkan rata-rata pengurangan impuritas (Gini atau entropy) pada setiap pemisahan yang dilakukan oleh pohon keputusan di dalam ensemble. Hasil analisis ditampilkan dalam bentuk visualisasi bar chart, yang menunjukkan fitur mana saja yang paling berpengaruh dalam menentukan prediksi ketepatan waktu kelulusan mahasiswa. Analisis ini membantu dalam memahami variabel mana yang paling relevan dan dapat dijadikan fokus dalam pengambilan keputusan atau pengembangan model lebih lanjut.
"""

# Feature Importance
feature_importances = best_rf_model.feature_importances_ # Changed 'final_model' to 'rf_model'
features = X_train.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)

# Visualisasi Feature Importance
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Feature Importance dari RandomForestClassifier')
plt.show()